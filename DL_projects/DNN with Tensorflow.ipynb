{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57610494",
   "metadata": {},
   "source": [
    "##### Boston Housing data set in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248088b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\srika\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b399d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023d5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c08337cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57026/57026 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cee493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(X_train, axis=0)\n",
    "train_std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe67b8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "         0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "         0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         0.22061726, -1.30850006],\n",
       "       ...,\n",
       "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "         0.07943894, -0.67776904],\n",
       "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -0.98764362,  0.42083466],\n",
       "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "         0.23317118, -1.15392266]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc7b721c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ed630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        Dense(20, activation=tf.nn.relu, input_shape=[len(X_train[0])]),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.optimizers.Adam(), loss = 'mae',\n",
    "                 metrics='mean_absolute_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82dc70bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch%100==0:\n",
    "            print(\"\")\n",
    "            print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "870ef054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\srika\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1118f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94861adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\srika\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\srika\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "12/12 [==============================] - ETA: 0s - loss: 21.4635 - mean_absolute_error: 21.4635 \n",
      "12/12 [==============================] - 3s 53ms/step - loss: 21.4635 - mean_absolute_error: 21.4635 - val_loss: 20.2585 - val_mean_absolute_error: 20.2585\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 21.1738 - mean_absolute_error: 21.1738 - val_loss: 19.9644 - val_mean_absolute_error: 19.9644\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 20.8783 - mean_absolute_error: 20.8783 - val_loss: 19.6652 - val_mean_absolute_error: 19.6652\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 20.5757 - mean_absolute_error: 20.5757 - val_loss: 19.3495 - val_mean_absolute_error: 19.3495\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 20.2581 - mean_absolute_error: 20.2581 - val_loss: 19.0154 - val_mean_absolute_error: 19.0154\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 19.9192 - mean_absolute_error: 19.9192 - val_loss: 18.6612 - val_mean_absolute_error: 18.6612\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 19.5681 - mean_absolute_error: 19.5681 - val_loss: 18.2793 - val_mean_absolute_error: 18.2793\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 19.1886 - mean_absolute_error: 19.1886 - val_loss: 17.8806 - val_mean_absolute_error: 17.8806\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 18.7913 - mean_absolute_error: 18.7913 - val_loss: 17.4637 - val_mean_absolute_error: 17.4637\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 18.3802 - mean_absolute_error: 18.3802 - val_loss: 17.0176 - val_mean_absolute_error: 17.0176\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 17.9308 - mean_absolute_error: 17.9308 - val_loss: 16.5501 - val_mean_absolute_error: 16.5501\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 17.4587 - mean_absolute_error: 17.4587 - val_loss: 16.0538 - val_mean_absolute_error: 16.0538\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 16.9598 - mean_absolute_error: 16.9598 - val_loss: 15.5472 - val_mean_absolute_error: 15.5472\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 16.4168 - mean_absolute_error: 16.4168 - val_loss: 15.0216 - val_mean_absolute_error: 15.0216\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 15.8633 - mean_absolute_error: 15.8633 - val_loss: 14.4755 - val_mean_absolute_error: 14.4755\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 15.3151 - mean_absolute_error: 15.3151 - val_loss: 13.8862 - val_mean_absolute_error: 13.8862\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 14.7373 - mean_absolute_error: 14.7373 - val_loss: 13.2760 - val_mean_absolute_error: 13.2760\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.1401 - mean_absolute_error: 14.1401 - val_loss: 12.6570 - val_mean_absolute_error: 12.6570\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.5179 - mean_absolute_error: 13.5179 - val_loss: 12.0043 - val_mean_absolute_error: 12.0043\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.8797 - mean_absolute_error: 12.8797 - val_loss: 11.3506 - val_mean_absolute_error: 11.3506\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.2873 - mean_absolute_error: 12.2873 - val_loss: 10.6932 - val_mean_absolute_error: 10.6932\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 11.7322 - mean_absolute_error: 11.7322 - val_loss: 10.1254 - val_mean_absolute_error: 10.1254\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.2316 - mean_absolute_error: 11.2316 - val_loss: 9.6714 - val_mean_absolute_error: 9.6714\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 10.7699 - mean_absolute_error: 10.7699 - val_loss: 9.2736 - val_mean_absolute_error: 9.2736\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 10.3555 - mean_absolute_error: 10.3555 - val_loss: 8.9644 - val_mean_absolute_error: 8.9644\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.9857 - mean_absolute_error: 9.9857 - val_loss: 8.7023 - val_mean_absolute_error: 8.7023\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.6361 - mean_absolute_error: 9.6361 - val_loss: 8.4589 - val_mean_absolute_error: 8.4589\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.3337 - mean_absolute_error: 9.3337 - val_loss: 8.2240 - val_mean_absolute_error: 8.2240\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.0358 - mean_absolute_error: 9.0358 - val_loss: 8.0137 - val_mean_absolute_error: 8.0137\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.7824 - mean_absolute_error: 8.7824 - val_loss: 7.8231 - val_mean_absolute_error: 7.8231\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.5371 - mean_absolute_error: 8.5371 - val_loss: 7.6380 - val_mean_absolute_error: 7.6380\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.3138 - mean_absolute_error: 8.3138 - val_loss: 7.4444 - val_mean_absolute_error: 7.4444\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.1112 - mean_absolute_error: 8.1112 - val_loss: 7.2481 - val_mean_absolute_error: 7.2481\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.9160 - mean_absolute_error: 7.9160 - val_loss: 7.0574 - val_mean_absolute_error: 7.0574\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.7174 - mean_absolute_error: 7.7174 - val_loss: 6.8767 - val_mean_absolute_error: 6.8767\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.5316 - mean_absolute_error: 7.5316 - val_loss: 6.6904 - val_mean_absolute_error: 6.6904\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.3422 - mean_absolute_error: 7.3422 - val_loss: 6.5061 - val_mean_absolute_error: 6.5061\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.1544 - mean_absolute_error: 7.1544 - val_loss: 6.3226 - val_mean_absolute_error: 6.3226\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.9719 - mean_absolute_error: 6.9719 - val_loss: 6.1473 - val_mean_absolute_error: 6.1473\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.8015 - mean_absolute_error: 6.8015 - val_loss: 5.9767 - val_mean_absolute_error: 5.9767\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.6277 - mean_absolute_error: 6.6277 - val_loss: 5.8010 - val_mean_absolute_error: 5.8010\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.4588 - mean_absolute_error: 6.4588 - val_loss: 5.6409 - val_mean_absolute_error: 5.6409\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.2875 - mean_absolute_error: 6.2875 - val_loss: 5.4967 - val_mean_absolute_error: 5.4967\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.1231 - mean_absolute_error: 6.1231 - val_loss: 5.3610 - val_mean_absolute_error: 5.3610\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.9589 - mean_absolute_error: 5.9589 - val_loss: 5.2417 - val_mean_absolute_error: 5.2417\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.7905 - mean_absolute_error: 5.7905 - val_loss: 5.1123 - val_mean_absolute_error: 5.1123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.6275 - mean_absolute_error: 5.6275 - val_loss: 5.0192 - val_mean_absolute_error: 5.0192\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5.4625 - mean_absolute_error: 5.4625 - val_loss: 4.9418 - val_mean_absolute_error: 4.9418\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.3045 - mean_absolute_error: 5.3045 - val_loss: 4.8590 - val_mean_absolute_error: 4.8590\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.1398 - mean_absolute_error: 5.1398 - val_loss: 4.7837 - val_mean_absolute_error: 4.7837\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.9721 - mean_absolute_error: 4.9721 - val_loss: 4.7273 - val_mean_absolute_error: 4.7273\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.8288 - mean_absolute_error: 4.8288 - val_loss: 4.6729 - val_mean_absolute_error: 4.6729\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.6700 - mean_absolute_error: 4.6700 - val_loss: 4.6332 - val_mean_absolute_error: 4.6332\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.5328 - mean_absolute_error: 4.5328 - val_loss: 4.5834 - val_mean_absolute_error: 4.5834\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.4094 - mean_absolute_error: 4.4094 - val_loss: 4.5131 - val_mean_absolute_error: 4.5131\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.2890 - mean_absolute_error: 4.2890 - val_loss: 4.4627 - val_mean_absolute_error: 4.4627\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.1858 - mean_absolute_error: 4.1858 - val_loss: 4.3803 - val_mean_absolute_error: 4.3803\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.1016 - mean_absolute_error: 4.1016 - val_loss: 4.3159 - val_mean_absolute_error: 4.3159\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.0303 - mean_absolute_error: 4.0303 - val_loss: 4.2715 - val_mean_absolute_error: 4.2715\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.9627 - mean_absolute_error: 3.9627 - val_loss: 4.2247 - val_mean_absolute_error: 4.2247\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.9090 - mean_absolute_error: 3.9090 - val_loss: 4.1767 - val_mean_absolute_error: 4.1767\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.8694 - mean_absolute_error: 3.8694 - val_loss: 4.1755 - val_mean_absolute_error: 4.1755\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.8284 - mean_absolute_error: 3.8284 - val_loss: 4.1419 - val_mean_absolute_error: 4.1419\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.8012 - mean_absolute_error: 3.8012 - val_loss: 4.1206 - val_mean_absolute_error: 4.1206\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.7733 - mean_absolute_error: 3.7733 - val_loss: 4.1084 - val_mean_absolute_error: 4.1084\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.7442 - mean_absolute_error: 3.7442 - val_loss: 4.0619 - val_mean_absolute_error: 4.0619\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.7192 - mean_absolute_error: 3.7192 - val_loss: 4.0067 - val_mean_absolute_error: 4.0067\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.6939 - mean_absolute_error: 3.6939 - val_loss: 3.9833 - val_mean_absolute_error: 3.9833\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.6713 - mean_absolute_error: 3.6713 - val_loss: 3.9711 - val_mean_absolute_error: 3.9711\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.6486 - mean_absolute_error: 3.6486 - val_loss: 3.9607 - val_mean_absolute_error: 3.9607\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.6326 - mean_absolute_error: 3.6326 - val_loss: 3.9220 - val_mean_absolute_error: 3.9220\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.6117 - mean_absolute_error: 3.6117 - val_loss: 3.9139 - val_mean_absolute_error: 3.9139\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.5927 - mean_absolute_error: 3.5927 - val_loss: 3.8742 - val_mean_absolute_error: 3.8742\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.5782 - mean_absolute_error: 3.5782 - val_loss: 3.8476 - val_mean_absolute_error: 3.8476\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.5638 - mean_absolute_error: 3.5638 - val_loss: 3.8279 - val_mean_absolute_error: 3.8279\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.5453 - mean_absolute_error: 3.5453 - val_loss: 3.8317 - val_mean_absolute_error: 3.8317\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.5270 - mean_absolute_error: 3.5270 - val_loss: 3.8225 - val_mean_absolute_error: 3.8225\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.5121 - mean_absolute_error: 3.5121 - val_loss: 3.8132 - val_mean_absolute_error: 3.8132\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.4972 - mean_absolute_error: 3.4972 - val_loss: 3.7473 - val_mean_absolute_error: 3.7473\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.4802 - mean_absolute_error: 3.4802 - val_loss: 3.7586 - val_mean_absolute_error: 3.7586\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.4587 - mean_absolute_error: 3.4587 - val_loss: 3.7502 - val_mean_absolute_error: 3.7502\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.4414 - mean_absolute_error: 3.4414 - val_loss: 3.7133 - val_mean_absolute_error: 3.7133\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.4230 - mean_absolute_error: 3.4230 - val_loss: 3.6965 - val_mean_absolute_error: 3.6965\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.4051 - mean_absolute_error: 3.4051 - val_loss: 3.6659 - val_mean_absolute_error: 3.6659\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.3890 - mean_absolute_error: 3.3890 - val_loss: 3.6611 - val_mean_absolute_error: 3.6611\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.3706 - mean_absolute_error: 3.3706 - val_loss: 3.6352 - val_mean_absolute_error: 3.6352\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.3554 - mean_absolute_error: 3.3554 - val_loss: 3.6206 - val_mean_absolute_error: 3.6206\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.3403 - mean_absolute_error: 3.3403 - val_loss: 3.5859 - val_mean_absolute_error: 3.5859\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.3269 - mean_absolute_error: 3.3269 - val_loss: 3.5889 - val_mean_absolute_error: 3.5889\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.3109 - mean_absolute_error: 3.3109 - val_loss: 3.5427 - val_mean_absolute_error: 3.5427\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.2941 - mean_absolute_error: 3.2941 - val_loss: 3.5280 - val_mean_absolute_error: 3.5280\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.2791 - mean_absolute_error: 3.2791 - val_loss: 3.5170 - val_mean_absolute_error: 3.5170\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.2650 - mean_absolute_error: 3.2650 - val_loss: 3.4861 - val_mean_absolute_error: 3.4861\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.2486 - mean_absolute_error: 3.2486 - val_loss: 3.4882 - val_mean_absolute_error: 3.4882\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.2322 - mean_absolute_error: 3.2322 - val_loss: 3.4525 - val_mean_absolute_error: 3.4525\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.2183 - mean_absolute_error: 3.2183 - val_loss: 3.4293 - val_mean_absolute_error: 3.4293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.2046 - mean_absolute_error: 3.2046 - val_loss: 3.4101 - val_mean_absolute_error: 3.4101\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.1856 - mean_absolute_error: 3.1856 - val_loss: 3.3993 - val_mean_absolute_error: 3.3993\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.1712 - mean_absolute_error: 3.1712 - val_loss: 3.3642 - val_mean_absolute_error: 3.3642\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.1574 - mean_absolute_error: 3.1574 - val_loss: 3.3530 - val_mean_absolute_error: 3.3530\n",
      "Epoch 101/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 3.8217 - mean_absolute_error: 3.8217\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.1414 - mean_absolute_error: 3.1414 - val_loss: 3.3715 - val_mean_absolute_error: 3.3715\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.1244 - mean_absolute_error: 3.1244 - val_loss: 3.3241 - val_mean_absolute_error: 3.3241\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.1035 - mean_absolute_error: 3.1035 - val_loss: 3.2929 - val_mean_absolute_error: 3.2929\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.0885 - mean_absolute_error: 3.0885 - val_loss: 3.2805 - val_mean_absolute_error: 3.2805\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.0773 - mean_absolute_error: 3.0773 - val_loss: 3.3022 - val_mean_absolute_error: 3.3022\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.0586 - mean_absolute_error: 3.0586 - val_loss: 3.2470 - val_mean_absolute_error: 3.2470\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.0450 - mean_absolute_error: 3.0450 - val_loss: 3.2466 - val_mean_absolute_error: 3.2466\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.0234 - mean_absolute_error: 3.0234 - val_loss: 3.2412 - val_mean_absolute_error: 3.2412\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.0106 - mean_absolute_error: 3.0106 - val_loss: 3.2274 - val_mean_absolute_error: 3.2274\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.9949 - mean_absolute_error: 2.9949 - val_loss: 3.2057 - val_mean_absolute_error: 3.2057\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.9807 - mean_absolute_error: 2.9807 - val_loss: 3.1822 - val_mean_absolute_error: 3.1822\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.9665 - mean_absolute_error: 2.9665 - val_loss: 3.1936 - val_mean_absolute_error: 3.1936\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.9521 - mean_absolute_error: 2.9521 - val_loss: 3.1732 - val_mean_absolute_error: 3.1732\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.9370 - mean_absolute_error: 2.9370 - val_loss: 3.1146 - val_mean_absolute_error: 3.1146\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.9207 - mean_absolute_error: 2.9207 - val_loss: 3.1051 - val_mean_absolute_error: 3.1051\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.9061 - mean_absolute_error: 2.9061 - val_loss: 3.1298 - val_mean_absolute_error: 3.1298\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.8856 - mean_absolute_error: 2.8856 - val_loss: 3.0832 - val_mean_absolute_error: 3.0832\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.8731 - mean_absolute_error: 2.8731 - val_loss: 3.0617 - val_mean_absolute_error: 3.0617\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.8576 - mean_absolute_error: 2.8576 - val_loss: 3.0509 - val_mean_absolute_error: 3.0509\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.8417 - mean_absolute_error: 2.8417 - val_loss: 3.0438 - val_mean_absolute_error: 3.0438\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.8251 - mean_absolute_error: 2.8251 - val_loss: 3.0308 - val_mean_absolute_error: 3.0308\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.8128 - mean_absolute_error: 2.8128 - val_loss: 2.9972 - val_mean_absolute_error: 2.9972\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7951 - mean_absolute_error: 2.7951 - val_loss: 2.9765 - val_mean_absolute_error: 2.9765\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7826 - mean_absolute_error: 2.7826 - val_loss: 2.9795 - val_mean_absolute_error: 2.9795\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.7645 - mean_absolute_error: 2.7645 - val_loss: 2.9584 - val_mean_absolute_error: 2.9584\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.7522 - mean_absolute_error: 2.7522 - val_loss: 2.9699 - val_mean_absolute_error: 2.9699\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7337 - mean_absolute_error: 2.7337 - val_loss: 2.9547 - val_mean_absolute_error: 2.9547\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7176 - mean_absolute_error: 2.7176 - val_loss: 2.9122 - val_mean_absolute_error: 2.9122\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.7066 - mean_absolute_error: 2.7066 - val_loss: 2.9052 - val_mean_absolute_error: 2.9052\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.6939 - mean_absolute_error: 2.6939 - val_loss: 2.8973 - val_mean_absolute_error: 2.8973\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.6783 - mean_absolute_error: 2.6783 - val_loss: 2.8889 - val_mean_absolute_error: 2.8889\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.6645 - mean_absolute_error: 2.6645 - val_loss: 2.9023 - val_mean_absolute_error: 2.9023\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.6497 - mean_absolute_error: 2.6497 - val_loss: 2.8918 - val_mean_absolute_error: 2.8918\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.6351 - mean_absolute_error: 2.6351 - val_loss: 2.8851 - val_mean_absolute_error: 2.8851\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.6233 - mean_absolute_error: 2.6233 - val_loss: 2.8456 - val_mean_absolute_error: 2.8456\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.6087 - mean_absolute_error: 2.6087 - val_loss: 2.8566 - val_mean_absolute_error: 2.8566\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.5969 - mean_absolute_error: 2.5969 - val_loss: 2.8459 - val_mean_absolute_error: 2.8459\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5871 - mean_absolute_error: 2.5871 - val_loss: 2.8566 - val_mean_absolute_error: 2.8566\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5810 - mean_absolute_error: 2.5810 - val_loss: 2.8583 - val_mean_absolute_error: 2.8583\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.5594 - mean_absolute_error: 2.5594 - val_loss: 2.8231 - val_mean_absolute_error: 2.8231\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5498 - mean_absolute_error: 2.5498 - val_loss: 2.7924 - val_mean_absolute_error: 2.7924\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5434 - mean_absolute_error: 2.5434 - val_loss: 2.7935 - val_mean_absolute_error: 2.7935\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.5253 - mean_absolute_error: 2.5253 - val_loss: 2.8165 - val_mean_absolute_error: 2.8165\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5161 - mean_absolute_error: 2.5161 - val_loss: 2.7824 - val_mean_absolute_error: 2.7824\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5075 - mean_absolute_error: 2.5075 - val_loss: 2.7546 - val_mean_absolute_error: 2.7546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.4985 - mean_absolute_error: 2.4985 - val_loss: 2.7850 - val_mean_absolute_error: 2.7850\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.4841 - mean_absolute_error: 2.4841 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.4777 - mean_absolute_error: 2.4777 - val_loss: 2.7434 - val_mean_absolute_error: 2.7434\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.4657 - mean_absolute_error: 2.4657 - val_loss: 2.7226 - val_mean_absolute_error: 2.7226\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.4511 - mean_absolute_error: 2.4511 - val_loss: 2.7506 - val_mean_absolute_error: 2.7506\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.4422 - mean_absolute_error: 2.4422 - val_loss: 2.7335 - val_mean_absolute_error: 2.7335\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.4376 - mean_absolute_error: 2.4376 - val_loss: 2.6834 - val_mean_absolute_error: 2.6834\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.4208 - mean_absolute_error: 2.4208 - val_loss: 2.6756 - val_mean_absolute_error: 2.6757\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.4111 - mean_absolute_error: 2.4111 - val_loss: 2.6749 - val_mean_absolute_error: 2.6749\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.4029 - mean_absolute_error: 2.4029 - val_loss: 2.6664 - val_mean_absolute_error: 2.6664\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.3906 - mean_absolute_error: 2.3906 - val_loss: 2.6392 - val_mean_absolute_error: 2.6392\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3799 - mean_absolute_error: 2.3799 - val_loss: 2.6424 - val_mean_absolute_error: 2.6424\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.3734 - mean_absolute_error: 2.3734 - val_loss: 2.6309 - val_mean_absolute_error: 2.6309\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.3630 - mean_absolute_error: 2.3630 - val_loss: 2.6253 - val_mean_absolute_error: 2.6253\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.3599 - mean_absolute_error: 2.3599 - val_loss: 2.6385 - val_mean_absolute_error: 2.6385\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.3498 - mean_absolute_error: 2.3498 - val_loss: 2.5954 - val_mean_absolute_error: 2.5954\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.3363 - mean_absolute_error: 2.3363 - val_loss: 2.6210 - val_mean_absolute_error: 2.6210\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3328 - mean_absolute_error: 2.3328 - val_loss: 2.5575 - val_mean_absolute_error: 2.5575\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3200 - mean_absolute_error: 2.3200 - val_loss: 2.5870 - val_mean_absolute_error: 2.5870\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3135 - mean_absolute_error: 2.3135 - val_loss: 2.5789 - val_mean_absolute_error: 2.5789\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.3048 - mean_absolute_error: 2.3048 - val_loss: 2.5415 - val_mean_absolute_error: 2.5415\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2956 - mean_absolute_error: 2.2956 - val_loss: 2.5581 - val_mean_absolute_error: 2.5581\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2932 - mean_absolute_error: 2.2932 - val_loss: 2.5651 - val_mean_absolute_error: 2.5651\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2865 - mean_absolute_error: 2.2865 - val_loss: 2.5027 - val_mean_absolute_error: 2.5027\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2880 - mean_absolute_error: 2.2880 - val_loss: 2.5681 - val_mean_absolute_error: 2.5681\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2718 - mean_absolute_error: 2.2718 - val_loss: 2.5018 - val_mean_absolute_error: 2.5018\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2625 - mean_absolute_error: 2.2625 - val_loss: 2.4967 - val_mean_absolute_error: 2.4967\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2591 - mean_absolute_error: 2.2591 - val_loss: 2.5072 - val_mean_absolute_error: 2.5072\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2533 - mean_absolute_error: 2.2533 - val_loss: 2.4511 - val_mean_absolute_error: 2.4511\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2575 - mean_absolute_error: 2.2575 - val_loss: 2.4488 - val_mean_absolute_error: 2.4488\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2393 - mean_absolute_error: 2.2393 - val_loss: 2.4782 - val_mean_absolute_error: 2.4782\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.2327 - mean_absolute_error: 2.2327 - val_loss: 2.4693 - val_mean_absolute_error: 2.4693\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2288 - mean_absolute_error: 2.2288 - val_loss: 2.4547 - val_mean_absolute_error: 2.4547\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2235 - mean_absolute_error: 2.2235 - val_loss: 2.4608 - val_mean_absolute_error: 2.4608\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.2162 - mean_absolute_error: 2.2162 - val_loss: 2.4301 - val_mean_absolute_error: 2.4301\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2102 - mean_absolute_error: 2.2102 - val_loss: 2.4464 - val_mean_absolute_error: 2.4464\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2063 - mean_absolute_error: 2.2063 - val_loss: 2.4240 - val_mean_absolute_error: 2.4240\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.2055 - mean_absolute_error: 2.2055 - val_loss: 2.3858 - val_mean_absolute_error: 2.3858\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1953 - mean_absolute_error: 2.1953 - val_loss: 2.4134 - val_mean_absolute_error: 2.4134\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1932 - mean_absolute_error: 2.1932 - val_loss: 2.4148 - val_mean_absolute_error: 2.4148\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1855 - mean_absolute_error: 2.1855 - val_loss: 2.3727 - val_mean_absolute_error: 2.3727\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1822 - mean_absolute_error: 2.1822 - val_loss: 2.3631 - val_mean_absolute_error: 2.3631\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.1795 - mean_absolute_error: 2.1795 - val_loss: 2.4097 - val_mean_absolute_error: 2.4097\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1734 - mean_absolute_error: 2.1734 - val_loss: 2.3593 - val_mean_absolute_error: 2.3593\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1722 - mean_absolute_error: 2.1722 - val_loss: 2.3329 - val_mean_absolute_error: 2.3329\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1715 - mean_absolute_error: 2.1715 - val_loss: 2.3572 - val_mean_absolute_error: 2.3572\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1702 - mean_absolute_error: 2.1702 - val_loss: 2.3855 - val_mean_absolute_error: 2.3855\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1656 - mean_absolute_error: 2.1656 - val_loss: 2.3149 - val_mean_absolute_error: 2.3149\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1571 - mean_absolute_error: 2.1571 - val_loss: 2.3311 - val_mean_absolute_error: 2.3311\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1563 - mean_absolute_error: 2.1563 - val_loss: 2.3405 - val_mean_absolute_error: 2.3405\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1535 - mean_absolute_error: 2.1535 - val_loss: 2.3049 - val_mean_absolute_error: 2.3049\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1446 - mean_absolute_error: 2.1446 - val_loss: 2.2961 - val_mean_absolute_error: 2.2961\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1452 - mean_absolute_error: 2.1452 - val_loss: 2.3059 - val_mean_absolute_error: 2.3059\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1389 - mean_absolute_error: 2.1389 - val_loss: 2.2607 - val_mean_absolute_error: 2.2607\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1346 - mean_absolute_error: 2.1346 - val_loss: 2.2906 - val_mean_absolute_error: 2.2906\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, validation_split=0.1,\n",
    "                   callbacks=[early_stop, PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555f7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38f5dc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.463497</td>\n",
       "      <td>21.463497</td>\n",
       "      <td>20.258528</td>\n",
       "      <td>20.258528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.173777</td>\n",
       "      <td>21.173777</td>\n",
       "      <td>19.964390</td>\n",
       "      <td>19.964390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.878296</td>\n",
       "      <td>20.878296</td>\n",
       "      <td>19.665203</td>\n",
       "      <td>19.665203</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.575686</td>\n",
       "      <td>20.575686</td>\n",
       "      <td>19.349546</td>\n",
       "      <td>19.349546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.258121</td>\n",
       "      <td>20.258120</td>\n",
       "      <td>19.015440</td>\n",
       "      <td>19.015440</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2.153465</td>\n",
       "      <td>2.153465</td>\n",
       "      <td>2.304935</td>\n",
       "      <td>2.304935</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2.144614</td>\n",
       "      <td>2.144614</td>\n",
       "      <td>2.296138</td>\n",
       "      <td>2.296138</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.145157</td>\n",
       "      <td>2.145157</td>\n",
       "      <td>2.305931</td>\n",
       "      <td>2.305931</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2.138869</td>\n",
       "      <td>2.138869</td>\n",
       "      <td>2.260655</td>\n",
       "      <td>2.260655</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2.134582</td>\n",
       "      <td>2.134582</td>\n",
       "      <td>2.290619</td>\n",
       "      <td>2.290619</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss  mean_absolute_error   val_loss  val_mean_absolute_error  epoch\n",
       "0    21.463497            21.463497  20.258528                20.258528      0\n",
       "1    21.173777            21.173777  19.964390                19.964390      1\n",
       "2    20.878296            20.878296  19.665203                19.665203      2\n",
       "3    20.575686            20.575686  19.349546                19.349546      3\n",
       "4    20.258121            20.258120  19.015440                19.015440      4\n",
       "..         ...                  ...        ...                      ...    ...\n",
       "195   2.153465             2.153465   2.304935                 2.304935    195\n",
       "196   2.144614             2.144614   2.296138                 2.296138    196\n",
       "197   2.145157             2.145157   2.305931                 2.305931    197\n",
       "198   2.138869             2.138869   2.260655                 2.260655    198\n",
       "199   2.134582             2.134582   2.290619                 2.290619    199\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2439c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['epoch'] = history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb11a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srika\\AppData\\Local\\Temp\\ipykernel_14304\\4057063224.py:1: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  mae_final = float(hist['val_mean_absolute_error'].tail(1))\n"
     ]
    }
   ],
   "source": [
    "mae_final = float(hist['val_mean_absolute_error'].tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a78202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8401668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mean absolute Error on validation set: 2.291\n"
     ]
    }
   ],
   "source": [
    "print('Final Mean absolute Error on validation set: {}'.format(round(mae_final, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d076d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96c8f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 2.7841 - mean_absolute_error: 2.7841\n"
     ]
    }
   ],
   "source": [
    "mae, _ = model.evaluate(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44952822",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmae = np.sqrt(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c82d5494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mean absolute  Error on test set: 2.784\n"
     ]
    }
   ],
   "source": [
    "print(' Mean absolute  Error on test set: {}'.format(round(mae, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6f947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
