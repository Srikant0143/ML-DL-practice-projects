{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "870fa112",
   "metadata": {},
   "source": [
    "### Introduction to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cb1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the TensorBoard and importing the necessary libraries\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53feec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\srika\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40eb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd622ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f748c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e11cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model with dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c08ba",
   "metadata": {},
   "source": [
    "- Create a sequential model\n",
    "- Flatten the input shape to a one-dimensional array\n",
    "- Add a dense layer with 512 units and ReLU activation\n",
    "- Add a dropout layer with a rate of 0.2 to prevent overfitting\n",
    "- Add a dense layer with 10 units and softmax activation for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb344f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "886c62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape = (28,28)))\n",
    "    model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0a8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model using TensorFlow and Keras callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "567320c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    '''\n",
    "    Create a model using the create_model() function\n",
    "    Compile the model with the Adam optimizer, sparse categorical cross-entropy loss, and accuracy as the metric\n",
    "    Specify the log directory for TensorBoard logs based on the current timestamp\n",
    "    Create a TensorBoard callback to log histograms for visualization\n",
    "    Fit the model to the training data (x_train and y_train) for 10 epochs, with validation data (x_test and y_test), and use the TensorBoard callback during training\n",
    "    Evaluate and print the test accuracy and loss\n",
    "    '''\n",
    "    models = create_model()\n",
    "    models.compile(optimizer='adam',\n",
    "                   loss = 'sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    models.fit(x_train, y_train, epochs=5, \n",
    "               validation_data=(x_test, y_test),\n",
    "              callbacks=[tensorboard_callback])\n",
    "    \n",
    "    test_loss, test_acc = models.evaluate(x_test, y_test, verbose=2)\n",
    "    print(\"\\nTest accuracy:\", test_acc)\n",
    "    print(\"\\nTest loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02104062",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4990 - accuracy: 0.8211 - val_loss: 0.4220 - val_accuracy: 0.8452\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3836 - accuracy: 0.8589 - val_loss: 0.3884 - val_accuracy: 0.8583\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3477 - accuracy: 0.8726 - val_loss: 0.3786 - val_accuracy: 0.8607\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3288 - accuracy: 0.8787 - val_loss: 0.3795 - val_accuracy: 0.8666\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3123 - accuracy: 0.8846 - val_loss: 0.3630 - val_accuracy: 0.8661\n",
      "313/313 - 1s - loss: 0.3630 - accuracy: 0.8661 - 1s/epoch - 4ms/step\n",
      "\n",
      "Test accuracy: 0.866100013256073\n",
      "\n",
      "Test loss: 0.3629540801048279\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b35b8a",
   "metadata": {},
   "source": [
    "### Launching the TensorBoard with Parameters\n",
    "- The --host 0.0.0.0 option specifies the host address to which TensorBoard is bound. In this case, it is set to bind to all available network interfaces -The --port 6006 specifies the port number on which TensorBoard will be accessible\n",
    "- The --logdir logs specifies the directory containing the log files generated by TensorFlow, which will be used as the data source for TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752b130",
   "metadata": {},
   "source": [
    "!tensorboard --host 0.0.0.0 --port 6006 --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "363bd02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 8280), started 0:03:07 ago. (Use '!kill 8280' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-877f1461cf5ab8e1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-877f1461cf5ab8e1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf22f6",
   "metadata": {},
   "source": [
    "A brief overview of the visualizations created in this example and the dashboards (tabs in top navigation bar) where they can be found:\n",
    "\n",
    "* **Scalars** show how the loss and metrics change with every epoch. You can use them to also track training speed, learning rate, and other scalar values. Scalars can be found in the **Time Series** or **Scalars** dashboards.\n",
    "* **Graphs** help you visualize your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly. Graphs can be found in the **Graphs** dashboard.\n",
    "* **Histograms** and **Distributions** show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way. Histograms can be found in the **Time Series** or **Histograms** dashboards. Distributions can be found in the **Distributions** dashboard.\n",
    "\n",
    "Additional TensorBoard dashboards are automatically enabled when you log other types of data. For example, the Keras TensorBoard callback lets you log images and embeddings as well. You can see what other dashboards are available in TensorBoard by clicking on the \"inactive\" dropdown towards the top right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42247e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
